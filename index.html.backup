<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="EigenGS: From Eigenspace to Gaussian Image Space">
  <meta name="keywords" content="EigenGS, Computer Vision, Machine Learning, PCA, Gaussian Splatting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EigenGS: From Eigenspace to Gaussian Image Space</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <style>
    body {
      font-family: 'Google Sans', sans-serif;
      margin: 0;
      padding: 0;
    }
    
    .hero {
      padding: 3rem 0;
    }
    
    .publication-title {
      margin-bottom: 1rem;
    }
    
    .publication-authors {
      margin-bottom: 1rem;
    }
    
    .author-block {
      margin-right: 10px;
    }
    
    .publication-links {
      margin-top: 2rem;
    }
    
    .link-block {
      margin: 0 5px;
    }
    
    footer {
      padding: 3rem 0;
      margin-top: 3rem;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EigenGS: From Eigenspace to Gaussian Image Space</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Lo-Wei Tai</a><sup>1</sup>
            </span>
            <!-- Add more authors as needed -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National Tsing Hua University, Taiwan</span>
            <!-- Add more affiliations as needed -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link (will be updated once available) -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.07446" class="button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/lwtai/EigenGS" class="button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Principal Component Analysis (PCA), a classical dimensionality reduction technique, and 2D Gaussian representation, an adaptation of 3D Gaussian Splatting for image representation, offer distinct approaches to modeling visual data. We present EigenGS, a novel method that bridges these paradigms through an efficient transformation pipeline connecting eigenspace and image-space Gaussian representations. Our approach enables instant initialization of Gaussian parameters for new images without requiring per-image optimization from scratch, dramatically accelerating convergence. EigenGS introduces a frequency-aware learning mechanism that encourages Gaussians to adapt to different scales, effectively modeling varied spatial frequencies and preventing artifacts in high-resolution reconstruction. Extensive experiments demonstrate that EigenGS not only achieves superior reconstruction quality compared to direct 2D Gaussian fitting but also reduces necessary parameter count and training time. The results highlight EigenGS's effectiveness and generalization ability across images with varying resolutions and diverse categories, making Gaussian-based image representation both high-quality and viable for real-time applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            <strong>EigenGS Representation</strong> by Lo-Wei Tai<br>
            This website template is based on <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  // Your arXiv paper is already published
  document.addEventListener('DOMContentLoaded', function() {
    // No need for dynamic updates as links are already set
    console.log('EigenGS paper website loaded');
  });
</script>

</body>
</html>